## Microsoft Azure Export for Terraform

A tool to bring your existing Azure resources under the management of Terraform.

## Goal

Azure Export for Terraform utilizes the [Terraform AzureRM provider](https://github.com/hashicorp/terraform-provider-azurerm) to export into Terraform state and generate the corresponding Terraform configuration. Both the Terraform state and configuration are expected to be consistent with the resources' remote state, i.e., `terraform plan` shows no diff. The user then is able to use Terraform to manage these resources.

## Non Goal

The Terraform configurations generated by `aztfexport` are not meant to be comprehensive and do not ensure that the infrastructure can be fully reproduced from said generated configurations. For details, please refer to the [limitation section](#limitation).

## Install

### From Release

Precompiled binaries and Window MSI are available at [Releases](https://github.com/Azure/aztfexport/releases).

### From Go toolchain

```bash
go install github.com/Azure/aztfexport@latest
```

### From Package Manager

#### Windows

```bash
winget install aztfexport
```

#### Homebrew (Linux/macOS)

```bash
brew install aztfexport
```

#### dnf (Linux)

Supported versions:

- RHEL 8 (amd64, arm64)
- RHEL 9 (amd64, arm64)

1. Import the Microsoft repository key:

    ```
    rpm --import https://packages.microsoft.com/keys/microsoft.asc
    ```

2. Add `packages-microsoft-com-prod` repository:

    ```
    ver=8 # or 9
    dnf install -y https://packages.microsoft.com/config/rhel/${ver}/packages-microsoft-prod.rpm
    ```

3. Install:

    ```
    dnf install aztfexport
    ```

#### apt (Linux)

Supported versions:

- Ubuntu 20.04 (amd64, arm64)
- Ubuntu 22.04 (amd64, arm64)

1. Import the Microsoft repository key:

    ```
    curl -sSL https://packages.microsoft.com/keys/microsoft.asc > /etc/apt/trusted.gpg.d/microsoft.asc
    ```

2. Add `packages-microsoft-com-prod` repository:

    ```
    ver=20.04 # or 22.04
    apt-add-repository https://packages.microsoft.com/ubuntu/${ver}/prod
    ```

3. Install:

    ```
    apt-get install aztfexport
    ```

#### AUR (Linux)

```bash
yay -S aztfexport
```

## Prerequisites

`aztfexport` requires a `terraform` executable installed in the `$PATH` with version `>= v0.12`.

## Usage

Follow this [authentication guide](https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs#authenticating-to-azure) from the Terraform AzureRM provider to authenticate to Azure.

Then run Azure Export for Terraform in the following format:
```terminal
aztfexport [command] [option] <scope>
```
Azure Export supports three variations of this core usage covered in these next sectionss: 
- `aztfexport resource <resource id>` to import a single resource
- `aztfexport resource-group <resource group name>` to import a resource group including child resources
- `aztfexport query <arg where predicate>` to import a customized set of resources by an Azure Resource Graph query

> ‚ùó Because each command has unique option flags available to it, `aztfexport --help` will **only list the available commands for the tool** and no option flags. **To see option flags for a given command**, please run `aztfexport [command] --help` instead.
### Resource

`aztfexport resource [option] <resource id>` exports a single resource by its Azure control plane ID:
```shell
aztfexport resource /subscriptions/0000/resourceGroups/myResourceGroup/providers/Microsoft.Compute/virtualMachines/myVM
```
This command will automatically identify the Terraform resource type (e.g. correctly identifies above resource as `azurerm_linux_virtual_machine`), and from its info generate a state file and Terraform configuration.

> ‚ùó For data plane only or property-like resources, the Azure resource ID is using a pesudo format, as is defined [here](https://github.com/magodo/aztft#pesudo-resource-id).

### Resource Group

`aztfexport resource-group [option] <resource group name>` exports a resource group and its included resources by the specified resource group name.

### Query

`aztfexport query [option] <arg where predicate>` exports a set of resources (and its including resources with option flag `--recursive`) by an Azure Resource Graph [`where` predicate](https://learn.microsoft.com/en-us/azure/data-explorer/kusto/query/whereoperator). Note that you can combine multiple conditions in one `where` predicate so long as you wrap the predicate in double quotes, e.g.  `aztfexport query "resourceGroup =~ 'my-rg' and type =~ 'microsoft.network/virtualnetworks'"`.

> üí° Resource group mode is the same as running `aztfexport query --recursive "resourceGroup =~ 'my-rg'"`, except it also exports the resource group itself.

`aztfexport` depends on `azlist`, which uses ARG behind the scenes. `azlist` will first make an ARG call with the given where predicate, then if `--recursive` is specified, it will recursively call "LIST" on the known child resource types. To read more about Azure Resource Graph visit the [ARG Documentation](https://learn.microsoft.com/en-us/azure/governance/resource-graph/).  
As of now ARG only returns ARM tracked resources, but not RP proxy resources (e.g. subnet, network security rules, storage containers, etc). Thus, if you run query mode on proxy resources (e.g. `aztfexport query type =~ "microsoft.network/virtualnetworks/subnets"`), it will return nothing since subnet is not an ARM tracked resource. A workaround is to query with a bigger scope (e.g. `type =~ "microsoft.network/virtualnetworks"`) in interactive mode, then manually remove the resources other than subnets.

### Mapping file

`aztfexport mapping-file [option] <resource mapping file>` exports a set of resources that is defined in the resource mapping file. You can generate the mapping file in all other modes (i.e. `resource`, `resource-group`, `query`) by specifying the `--generate-mapping-file` option when running non-interactively, or press <kbd>s</kbd> when running interactively in the resource list view. Also, each run of `aztfexport` will generate the resource mapping file for you, to record what resources have been imported.

The format of the mapping file is defined below:

```json
{
    "<Azure resource id1>": {
        "resource_type" : "<terraform resource type>",
        "resource_name" : "<terraform resource name>",
        "resource_id"   : "<terraform resource id>"
    },
    "<Azure resource id2>": {
        "resource_type" : "<terraform resource type>",
        "resource_name" : "<terraform resource name>",
        "resource_id"   : "<terraform resource id>"
    },
    ...
}
```

An example mapping file:

```json
{
	"/subscriptions/0000/resourceGroups/aztfexport-vmdisk": {
		"resource_id": "/subscriptions/0000/resourceGroups/aztfexport-vmdisk",
		"resource_type": "azurerm_resource_group",
		"resource_name": "res-1"
	},
	"/subscriptions/0000/resourceGroups/aztfexport-vmdisk/providers/Microsoft.Compute/disks/aztfexport-test-test": {
		"resource_id": "/subscriptions/0000/resourceGroups/aztfexport-vmdisk/providers/Microsoft.Compute/disks/aztfexport-test-test",
		"resource_type": "azurerm_managed_disk",
		"resource_name": "res-2"
	},
	"/subscriptions/0000/resourceGroups/aztfexport-vmdisk/providers/Microsoft.Compute/virtualMachines/aztfexport-test-test": {
		"resource_id": "/subscriptions/0000/resourceGroups/aztfexport-vmdisk/providers/Microsoft.Compute/virtualMachines/aztfexport-test-test",
		"resource_type": "azurerm_linux_virtual_machine",
		"resource_name": "res-3"
	}
}
```

If your use cases require pre-export modifications, you are not only welcome but also encouraged to manually construct or edit the mapping file. You could want to modify the mapping file if you:
- Have many resources in a resource group but only wish to export a select few
- Wish to rename all your resources in a compliant manner
- Want to manually discover resources under a given resource type (i.e. networking or compute)
- And other workflows you might discover!

Note that only the object value in the mapping file matters, while the key just plays as an identifier in this mode. 

### HCL Only

For any of the aforementioned modes (`resource`, `resource-group`, `query`, `mapping-file`), users can add the `--hcl-only` flag:
```terminal
aztfexport [command] --hcl-only [other options] <scope>
```
Though `aztfexport` will by default export a state file, the `--hcl-only` flag will result in only the following being generated:
- Any generated `.tf` HCL files
- (Planned for 0.10, not true as of 0.9) The mapping file `.json`
- (Planned for 0.10, not true as of 0.9) Any skipped resources in a `.txt`

This helps for scenarios where you may not need the state or are not sure you want to generate the state. If you then wish to export all of the generated configuration to state, you can rerun the tool and utilize `aztfexport mapping-file` to do so.  
> üí° `--hcl-only` must target an empty directory to avoid making unwanted changes to preexisting state during the export stage (thus it will not work with `--append`, but will work with `--overwrite`). Use the `-o` flag to specify an empty directory, or if the directory does not exist, it will be created for you.

### Interactive vs Non-Interactive

By default `aztfexport` runs in interactive mode, whilst you can also run in non-interactive mode by adding the `--non-interactive`/`-n` option.

#### Interactive mode

In interactive mode, `aztfexport` lists all the resources residing in the specified resource group or customized set.  
The following is a comprehensive list of possible commands in interactive mode. All keystrokes that perform the same action are listed together.  

- <kbd>&#8593;</kbd><kbd>k</kbd> navigate up in the resource list
- <kbd>&#8595;</kbd><kbd>j</kbd> navigate down in the resource list
- <kbd>&#8592;</kbd><kbd>h</kbd><kbd>PgUp</kbd> goes to previous page in the resource list
- <kbd>&#8594;</kbd><kbd>l</kbd><kbd>PgDn</kbd>  goes to next page in the resource list
- <kbd>g</kbd><kbd>Home</kbd> jumps to the start of the resource list
- <kbd>G</kbd><kbd>End</kbd> jumps to the end of the resource list
- <kbd>/</kbd> allows you to define/apply a filter by text on the resource list
- <kbd>Esc</kbd> clears any current filter
- <kbd>Delete</kbd> skips the currently highlighted item and it will not be exported when <kbd>w</kbd> is pressed. If you skip a resource on accident, press <kbd>Delete</kbd> again to recover it.
- <kbd>s</kbd> saves a [mapping file](###mapping-file) of the resource list. This file's generated list is not affected by filtering, but is affected by skipping.
- <kbd>w</kbd> exports resources to state (if `--hcl-only` is not selected) and generates the config
- <kbd>r</kbd> shows possible recommendations for a resource
- <kbd>e</kbd> shows errors (if any) on exporting a resource
- <kbd>q</kbd> quits out of interactive mode
- <kbd>?</kbd> opens help

For each resource, `aztfexport` will try to recognize the corresponding Terraform resource type. If it finds one, the line will be prefixed by a üí° as an indicator. Otherwise, user is expected to input the Terraform resource address in form of `<resource type>.<resource name>` (e.g. `azurerm_linux_virtual_machine.test`). Users can press <kbd>r</kbd> to see the possible resource type(s) for the selected resource.

In some cases, there are Azure resources that have no corresponding Terraform resources (e.g. due to lacks of Terraform support). Some resources might also be created as a side effect of provisioning another resource (e.g. the OS Disk resource is created automatically when provisioning a VM). In such cases, you can skip these resources without typing anything.

After going through all the resources to be imported, press <kbd>w</kbd> to begin generating the Terraform configuration and (if `--hcl-only` is not selected) importing to Terraform state.

#### Non-Interactive mode

In non-interactive mode, `aztfexport` only imports recognized resources, and skips all others. Users can further specify the `--continue`/`-k` option to make the tool continue even on hitting any import error.

### Remote Backend

By default `aztfexport` uses a local backend to store the state file, but it is also possible to use a remote backend via the `--backend-type` and `--backend-config` options. Refer to the [Terraform backend documentation](https://www.terraform.io/language/settings/backends) to identify your type and config values.

For example, to export to an [`azurerm` backend](https://www.terraform.io/language/settings/backends/azurerm#azurerm) (in this case, an Azure storage account):

```shell
aztfexport [subcommand] --backend-type=azurerm --backend-config=resource_group_name=<resource group name> --backend-config=storage_account_name=<account name> --backend-config=container_name=<container name> --backend-config=key=terraform.tfstate 
```
> üí° Note that if the backend state already exists, `aztfexport` will merge the new resources to the existing state automatically. You do not need to specify the `--append` option.

You can also bring your own customized `provider.tf` or `terraform.tf` file with a predefined `terraform` or `provider` block; as of `v0.10` you are required to use the `--append` flag, but with the next release we hope to remove the need to use the flag to export to a backend. Be aware that your provider version should match the `aztfexport` version of AzureRM when exporting or the command will fail.

### Export Into Existing Local State

When exporting to a backend, `aztfexport` will by default ensure the output directory is empty. This is to avoid any conflicts happen for existing user files, including the terraform configuration, provider configuration, the state file, etc. As a result, `aztfexport` generates a new workspace for users.

If you instead wish to import resources to an existing state file via `aztfexport`, use the `--append` option. When this option is run, `aztfexport` will check if there is a preexisting `provider` and `terraform` block (and create a file for each respectively if either does not exist). Then it proceeds with exporting.

This means that if the output directory has a state file, any resource exported by `aztfexport` will be imported into the state file. Furthermore, the file generated by `aztfexport` in this case will have a `.aztfexport` suffix before the extension (e.g. `main.aztfexport.tf`), to avoid potential file name conflicts. If you run `aztfexport --append` multiple times, the generated config in `main.aztfexport.tf` will append to itself in each run.

### Config

`aztfexport` will create a configuration file at `$HOME/.aztfexport/config.json`. This file is aim to be managed by command `aztfexport config [subcommand]`, which includes following subcommands:

- `get`: Get a config item
- `set`: Set a config item
- `show`: Show the full configuration

Currently, the following config items are supported:

- `installation_id`: A UUID created on first run. If there is Azure CLI or Azure Powershell installed on the current machine, the UUID will be the same value among these tools. Otherwise, a new one will be created. This is used as an identifier in the telemetry trace.
- `telemetry_enabled`: Enables telemetry. We use telemetry to identify issues and areas for improvement, in order to optimize this tool for better performance, reliability, and user experience. If you wish to disable our telemetry, set this to false.

## How it Works

`aztfexport` leverages [`aztft`](https://github.com/magodo/aztft) to identify the Terraform resource type corresponding to an Azure resource ID. Then it runs `terraform import` under the hood to import each resource. Afterwards, it runs [`tfadd`](https://github.com/magodo/tfadd) to generate the Terraform HCL code for each imported resource.

## Demo

[![asciicast](https://asciinema.org/a/sKYqzSiE5bpBJCB4BM2HjvF4j.svg)](https://asciinema.org/a/sKYqzSiE5bpBJCB4BM2HjvF4j)

## Limitations

We do not guarantee that redeploying Terraform configurations generated by `aztfexport` will reproduce the exact same infrastructure. This is due to known limitations that we detail below along with subsequently recommended actions. We will do our best to update this section as we discover new limitations.

### Omitted Properties

When generating the Terraform configuration, not all properties of the resource are exported for different reasons.

One reason is because there are flexible cross-property constraints defined in the AzureRM Terraform provider. E.g. `property_a` conflicts with `property_b`. This might due to the nature of the API, or might be due to some deprecation process of the provider (e.g. `property_a` is deprecated in favor of `property_b`, but kept for backwards compatibility). These constraints require some properties to be absent in the Terraform configuration; otherwise, the configuration is not valid and will fail during `terraform validate`. For an example refer to [this schema for the azurerm_storage_blob resource](https://github.com/hashicorp/terraform-provider-azurerm/blob/8c7510d8b6ccf5098c7f05bd8c013a0e579a2e80/internal/services/storage/storage_blob_resource.go#L107-L126). If a user wishes to attempt to mitigate this issue, they would ultimately need to refer to the AzureRM documentation to know what, if any, properties are ommitted and what the current property value would entail.

Another reason is that an Azure resource can be a property of its parent resource (e.g. `azurerm_subnet` can be its own resource, or be a property of `azurerm_virtual_network`). Per Terraform's best practice, users should only use one of the forms, not both. `aztfexport` chooses to always generate all the resources, but omit the property in the parent resource that represents the child resource. While this is not necessarily going to affect the validity of the generated resource, we recommend you refactor child resources to a property of the parent resource if that is your current practice.


## Additional Resources

- [The aztfexport Github Page](https://azure.github.io/aztfexport): Everything about aztfexport, including comparisons with other existing import solutions.
- [aztft](https://github.com/magodo/aztft): A Go program and library for identifying the correct Terraform AzureRM provider resource type on the Azure resource id.
- [tfadd](https://github.com/magodo/tfadd): A Go program and library for generating Terraform configuration from Terraform state.
